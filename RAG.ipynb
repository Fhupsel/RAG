{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOk4NGhVCGbSUkqB+SPDHod",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fhupsel/RAG/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar bibliotecas necessárias (caso ainda não tenha)\n",
        "# !pip install langchain langchain-community chromadb sentence-transformers pypdf transformers huggingface_hub -q\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "\n",
        "# Configurar modelo de embeddings gratuito\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Definir modelo de LLM gratuito do Hugging Face\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('API_KEY')\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_length\": 200}\n",
        ")\n",
        "\n",
        "# Carregar o PDF para RAG\n",
        "pdf_path = \"/content/DOC-SF238339076816-20230503.pdf\"\n",
        "loader = PyPDFLoader(pdf_path, extract_images=False)\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "# Separar o texto em chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=4000,  # Define o tamanho dos fragmentos\n",
        "    chunk_overlap=20,  # Sobreposição entre os fragmentos\n",
        "    length_function=len,\n",
        "    add_start_index=True,\n",
        ")\n",
        "chunks = text_splitter.split_documents(pages)\n",
        "\n",
        "# Criar o banco de vetores e persistir\n",
        "vectordb = Chroma.from_documents(chunks, embedding=embeddings_model, persist_directory=\"text_index\")\n",
        "vectordb.persist()\n",
        "\n",
        "# Configurar o retriever\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# Criar pipeline de QA\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
      ],
      "metadata": {
        "id": "JLLcZ4C9toKf",
        "collapsed": true
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(question):\n",
        "    context = retriever.get_relevant_documents(question)\n",
        "    answer = chain({'input_documents': context, 'question': question}, return_only_outputs=True)['output_text']\n",
        "    return answer"
      ],
      "metadata": {
        "id": "ltwK6ew7WBz2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_question = input(\"User: \")\n",
        "response = ask(user_question)\n",
        "# Quais os principais pontos da lei que devo me atentar?\n",
        "print(response)"
      ],
      "metadata": {
        "id": "mmYpwiH3RzoX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}